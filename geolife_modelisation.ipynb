{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1MN50HHUQNzfFMdK0WwJwzOq3V-zecVBa","authorship_tag":"ABX9TyN9xXo+lIKHXHHujCWX935Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import sys\n","import pandas as pd\n","import os\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import StratifiedShuffleSplit\n","import numpy as np\n","from google.colab import drive\n","import sys\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OChMyD8KT9CF","executionInfo":{"status":"ok","timestamp":1715857337539,"user_tz":-120,"elapsed":16072,"user":{"displayName":"Romain","userId":"07474121649826546243"}},"outputId":"719dddf2-7c08-48db-e13f-08acd8ab8bea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# On importe metadata_train\n","PA_metadata_train=pd.read_parquet(\"/content/drive/MyDrive/data/metadata/PA_metadata_train.parquet\",columns=['surveyId','speciesId'])\n","PA_metadata_train['speciesId'] = PA_metadata_train['speciesId'].astype(int).astype(str)\n","\n","# Count the occurrences of each speciesId\n","species_counts = PA_metadata_train['speciesId'].value_counts()\n","\n","# Filter the speciesId values that appear more than 300 times\n","# filtered_species = species_counts[species_counts > 300].index\n","\n","# Subset the dataset to keep only the rows with the filtered speciesId values\n","# PA_metadata_train = PA_metadata_train[PA_metadata_train['speciesId'].isin(filtered_species)]\n","\n","# Concatenante in list all speciesId for each surveyId\n","PA_metadata_train = PA_metadata_train.groupby('surveyId')['speciesId'].apply(list).reset_index()\n","\n","# On importe metadata_train\n","PA_metadata_test=pd.read_parquet(\"/content/drive/MyDrive/data/metadata/PA_metadata_test.parquet\",columns=['surveyId'])\n","\n","#train_labels_list = [[label] for label in train_labels]\n","#val_labels_list = [[label] for label in val_labels]"],"metadata":{"id":"JBotBAWQzv-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_image_paths(survey_id, rgb_dir, nir_dir):\n","    # Convert the survey_id to a string\n","    survey_id_str = str(survey_id)\n","\n","    # Extract the last 4 characters and split them into two subdirectories\n","    sub_dir1 = survey_id_str[-4:-2]\n","    sub_dir2 = survey_id_str[-2:]\n","\n","    # Create the image name using the last 6 characters of the survey_id\n","    image_name = f\"{survey_id_str}.jpeg\"\n","\n","    # Construct the RGB image path by joining the rgb_dir, sub_dir2, sub_dir1, and image_name\n","    rgb_image_path = os.path.join(rgb_dir, sub_dir2, sub_dir1, image_name)\n","\n","    # Construct the NIR image path by joining the nir_dir, sub_dir2, sub_dir1, and image_name\n","    nir_image_path = os.path.join(nir_dir, sub_dir2, sub_dir1, image_name)\n","\n","    # Return the RGB and NIR image paths as a tuple\n","    return rgb_image_path, nir_image_path\n","\n","def create_dataset_train(metadata_df, rgb_dir, nir_dir):\n","    # Initialize empty lists to store RGB image paths, NIR image paths, and labels\n","    rgb_image_paths = []\n","    nir_image_paths = []\n","\n","    labels = []\n","\n","    # Iterate over each row in the metadata DataFrame\n","    for _, row in metadata_df.iterrows():\n","        # Get the survey_id from the current row\n","        survey_id = row['surveyId']\n","\n","        # Call the get_image_paths function to get the RGB and NIR image paths for the current survey_id\n","        rgb_path, nir_path = get_image_paths(survey_id, rgb_dir, nir_dir)\n","\n","        # Append the RGB image path to the rgb_image_paths list\n","        rgb_image_paths.append(rgb_path)\n","\n","        # Append the NIR image path to the nir_image_paths list\n","        nir_image_paths.append(nir_path)\n","\n","        # Append the speciesId from the current row to the labels list\n","        labels.append(row['speciesId'])\n","\n","    # Return the lists of RGB image paths, NIR image paths, and labels as a tuple\n","    return rgb_image_paths, nir_image_paths, labels\n","\n","def create_dataset_test(metadata_df, rgb_dir, nir_dir):\n","  # Initialize empty lists to store RGB image paths, NIR image paths, and labels\n","  rgb_image_paths = []\n","  nir_image_paths = []\n","\n","  # Iterate over each row in the metadata DataFrame\n","  for _, row in metadata_df.iterrows():\n","      # Get the survey_id from the current row\n","      survey_id = row['surveyId']\n","\n","      # Call the get_image_paths function to get the RGB and NIR image paths for the current survey_id\n","      rgb_path, nir_path = get_image_paths(survey_id, rgb_dir, nir_dir)\n","\n","      # Append the RGB image path to the rgb_image_paths list\n","      rgb_image_paths.append(rgb_path)\n","\n","      # Append the NIR image path to the nir_image_paths list\n","      nir_image_paths.append(nir_path)\n","\n","  # Return the lists of RGB image paths, NIR image paths, and labels as a tuple\n","  return rgb_image_paths, nir_image_paths"],"metadata":{"id":"GTJJiteBzSZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the PA train dataset\n","rgb_train_paths, nir_train_paths, train_labels = create_dataset_train(\n","    PA_metadata_train,\n","    rgb_dir='/content/drive/MyDrive/data/SatellitePatches/pa_train_patches_rgb',\n","    nir_dir='/content/drive/MyDrive/data/SatellitePatches/pa_train_patches_nir'\n",")\n","\n","rgb_test_paths, nir_test_paths = create_dataset_test(\n","    PA_metadata_test,\n","    rgb_dir='/content/drive/MyDrive/data/SatellitePatches/pa_test_patches_rgb',\n","    nir_dir='/content/drive/MyDrive/data/SatellitePatches/pa_test_patches_nir'\n",")\n","\n","# Split the paths and labels into train and validation sets\n","#rgb_train_paths, rgb_val_paths, nir_train_paths, nir_val_paths, train_labels, val_labels = train_test_split(\n","#    rgb_train_paths, nir_train_paths, train_labels, test_size=0.2, random_state=42\n","#)\n"],"metadata":{"id":"H8__Zz1Z2VGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train_labels_list = [[label] for label in train_labels]\n","#val_labels_list = [[label] for label in val_labels]"],"metadata":{"id":"LgmJ0NTa56JE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert labels to multi-label binary format\n","mlb = MultiLabelBinarizer()\n","train_labels_bin = mlb.fit_transform(train_labels)\n","#val_labels_bin = mlb.transform(val_labels)"],"metadata":{"id":"AxqDSXvZK0Oj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_and_preprocess_image_train(rgb_path, nir_path, label):\n","    rgb_image = tf.io.read_file(rgb_path)\n","    rgb_image = tf.image.decode_jpeg(rgb_image, channels=3)\n","    rgb_image = tf.image.resize(rgb_image, (128, 128))  # Resize to match the input shape\n","    rgb_image = tf.cast(rgb_image, tf.float32) / 255.0  # Normalize pixel values\n","\n","    nir_image = tf.io.read_file(nir_path)\n","    nir_image = tf.image.decode_jpeg(nir_image, channels=1)  # Load as grayscale image with a single channel\n","    nir_image = tf.image.resize(nir_image, (128, 128))  # Resize to match the input shape\n","    nir_image = tf.cast(nir_image, tf.float32) / 255.0  # Normalize pixel values\n","\n","    return (rgb_image, nir_image), label  # Return a single tuple containing the RGB image, NIR image, and label\n","\n","def load_and_preprocess_image_test(rgb_path, nir_path):\n","  rgb_image = tf.io.read_file(rgb_path)\n","  rgb_image = tf.image.decode_jpeg(rgb_image, channels=3)\n","  rgb_image = tf.image.resize(rgb_image, (128, 128))  # Resize to match the input shape\n","  rgb_image = tf.cast(rgb_image, tf.float32) / 255.0  # Normalize pixel values\n","\n","  nir_image = tf.io.read_file(nir_path)\n","  nir_image = tf.image.decode_jpeg(nir_image, channels=1)  # Load as grayscale image with a single channel\n","  nir_image = tf.image.resize(nir_image, (128, 128))  # Resize to match the input shape\n","  nir_image = tf.cast(nir_image, tf.float32) / 255.0  # Normalize pixel values\n","\n","  return (rgb_image, nir_image)  # Return a single tuple containing the RGB image and NIR image\n","\n","\n","PA_train_dataset = tf.data.Dataset.from_tensor_slices((\n","    tf.constant(rgb_train_paths, dtype=tf.string),\n","    tf.constant(nir_train_paths, dtype=tf.string),\n","    tf.constant(train_labels_bin, dtype=tf.int64)\n","))\n","\n","PA_test_dataset = tf.data.Dataset.from_tensor_slices((\n","    tf.constant(rgb_test_paths, dtype=tf.string),\n","    tf.constant(nir_test_paths, dtype=tf.string)\n","))\n","\n","PA_train_dataset = PA_train_dataset.map(load_and_preprocess_image_train).cache()\n","PA_test_dataset = PA_test_dataset.map(load_and_preprocess_image_test).cache()\n","\n","batch_size = 256\n","PA_train_dataset = PA_train_dataset.shuffle(buffer_size=2000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","test_dataset = PA_test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","#PA_val_dataset = PA_val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"mFDPPBMiztec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assume you have already created the list of RGB image paths named 'rgb_image_paths'\n","\n","# Count the number of existing and non-existing paths\n","#existing_paths = 0\n","#non_existing_paths = 0\n","\n","#for path in rgb_train_paths:\n","#    if os.path.exists(path):\n","#        existing_paths += 1\n","#    else:\n","#        non_existing_paths += 1\n","\n","#print(f\"Number of existing paths: {existing_paths}\")\n","#print(f\"Number of non-existing paths: {non_existing_paths}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abi2dXx3JzoB","executionInfo":{"status":"ok","timestamp":1714578112668,"user_tz":-120,"elapsed":341804,"user":{"displayName":"Romain","userId":"07474121649826546243"}},"outputId":"443e54e6-9d67-48b6-ea7e-ab13a88937b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of existing paths: 1483637\n","Number of non-existing paths: 0\n"]}]},{"cell_type":"code","source":["def visualize_dataset(dataset, num_samples):\n","    plt.figure(figsize=(10, 10))\n","    for i, (rgb_image_path, nir_image_path, label) in enumerate(dataset.shuffle(1000).take(num_samples)):\n","        # Read RGB image from path\n","        rgb_image = tf.io.read_file(rgb_image_path.numpy().decode('utf-8'))\n","        rgb_image = tf.image.decode_jpeg(rgb_image, channels=3)\n","\n","        # Read NIR image from path\n","        nir_image = tf.io.read_file(nir_image_path.numpy().decode('utf-8'))\n","        nir_image = tf.image.decode_jpeg(nir_image, channels=1)\n","        nir_image = tf.image.grayscale_to_rgb(nir_image)\n","\n","        # Display RGB image\n","        plt.subplot(2, num_samples, i+1)\n","        plt.imshow(rgb_image.numpy().astype(\"uint8\"))\n","        plt.title(f\"RGB - Label: {label.numpy()}\")\n","        plt.axis(\"off\")\n","\n","        # Display NIR image\n","        plt.subplot(2, num_samples, i+num_samples+1)\n","        plt.imshow(nir_image.numpy().astype(\"uint8\"))\n","        plt.title(f\"NIR - Label: {label.numpy()}\")\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Assume you have already created the train_dataset using the previous code\n","\n","# Preprocess the dataset for visualization\n","#vis_dataset = PA_train_datasets.map(lambda rgb_image_path, nir_image_path, label: (rgb_image_path, nir_image_path, label))\n","\n","# Visualize a few random samples from the dataset\n","#num_samples_to_visualize = 5\n","#visualize_dataset(vis_dataset, num_samples_to_visualize)"],"metadata":{"id":"yG5hGPWEK9g8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Transfer Learning with Resnet-50 on RGB and NIR model"],"metadata":{"id":"lb7TNhAe8FSw"}},{"cell_type":"markdown","source":["## Définition des modèles individuelles"],"metadata":{"id":"7W8GNMhz3Hin"}},{"cell_type":"code","source":["print(tf.config.list_physical_devices('GPU'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tzzH7e8uWZQ","executionInfo":{"status":"ok","timestamp":1715857355804,"user_tz":-120,"elapsed":9,"user":{"displayName":"Romain","userId":"07474121649826546243"}},"outputId":"dcfa7a7f-788b-49e4-d41f-9015bdcc7b6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import Input,Sequential,Model,models\n","from tensorflow.keras.layers import Lambda, Flatten, BatchNormalization, Dense, Dropout, Concatenate\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import Callback"],"metadata":{"id":"Mgq7tHJgDBao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Définition de la taille cible des images en entrée du modèle\n","count_species=train_labels_bin.shape[1]\n","\n","# Définition des entrées du modèle\n","rgb_input = Input(shape=(128,128, 3), name='rgb_input') # RGB donc 3 canaux\n","nir_input = Input(shape=(128,128, 1), name='nir_input') # NIR, nuance de gris donc un canal\n","\n","# Conversion de l'image NIR en image RGB\n","# Resnet a été entrainé sur du RGB avec les weights provenant de imagenet\n","nir_rgb = Lambda(lambda x: tf.image.grayscale_to_rgb(x))(nir_input)\n","\n","# On définit les deux modèles ResNet, il faut en créer deux pour éviter\n","# la duplication des noms dans les layers\n","rgb_resnet_model = ResNet50(weights=None, include_top=False, input_tensor=rgb_input)\n","nir_resnet_model = ResNet50(weights=None, include_top=False, input_tensor=nir_rgb)\n","\n","# Freeze the layers of the ResNet50 base model for RGB model\n","for model in [rgb_resnet_model,nir_resnet_model]:\n","  for layer in model.layers[:143]:\n","      layer.trainable = False\n","\n","# Define the RGB model\n","rgb_model = Sequential()\n","rgb_model.add(rgb_resnet_model)\n","rgb_model.add(Flatten())\n","rgb_model.add(BatchNormalization())\n","rgb_model.add(Dense(256, activation='relu'))\n","rgb_model.add(Dropout(0.5))\n","rgb_model.add(BatchNormalization())\n","rgb_model.add(Dense(128, activation='relu'))\n","rgb_model.add(Dropout(0.5))\n","rgb_model.add(BatchNormalization())\n","rgb_model.add(Dense(64, activation='relu'))\n","rgb_model.add(Dropout(0.5))\n","rgb_model.add(BatchNormalization())\n","\n","# Define the NIR model\n","nir_model = Sequential()\n","nir_model.add(nir_resnet_model)\n","nir_model.add(Flatten())\n","nir_model.add(BatchNormalization())\n","nir_model.add(Dense(256, activation='relu'))\n","nir_model.add(Dropout(0.5))\n","nir_model.add(BatchNormalization())\n","nir_model.add(Dense(128, activation='relu'))\n","nir_model.add(Dropout(0.5))\n","nir_model.add(BatchNormalization())\n","nir_model.add(Dense(64, activation='relu'))\n","nir_model.add(Dropout(0.5))\n","nir_model.add(BatchNormalization())\n","\n","# Concatenate the two models\n","concatenated = Concatenate()([rgb_model(rgb_input), nir_model(nir_input)])\n","\n","# Define the output layer\n","output = Dense(count_species, activation='sigmoid')(concatenated)\n","\n","# Define the model\n","patch_model = Model(inputs=[rgb_input, nir_input], outputs=output)"],"metadata":{"id":"vYwtACRI7pnH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Définition callbacks et autres paramètres"],"metadata":{"id":"1pgmMoJCBIht"}},{"cell_type":"code","source":["from tensorflow.keras import callbacks\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","#Définition d'un callback de sauvegarde du modèle\n","# Ce callback permet de sauvegarder le modèle à chaque époque si la précision sur le jeu de validation a augmenté par rapport à l'époque précédente\n","\n","# Création du callback ModelCheckpoint\n","check_point = callbacks.ModelCheckpoint(filepath=\"/content/drive/MyDrive/mémoire/geolife_model_1505\",\n","                                        monitor=\"loss\",\n","                                        mode=\"min\",\n","                                        save_best_only=True,\n","                                        overwrite=True)\n","\n","# Define the early stopping callback\n","early_stopping = EarlyStopping(\n","    monitor='loss',  # monitor training loss\n","    min_delta=0,  # minimum change in loss to qualify as an improvement\n","    patience=3,  # number of epochs with no improvement after which training will be stopped\n","    verbose=1  # verbosity mode\n",")\n","\n","\n","# Explication des paramètres utilisés :\n","# - filepath : chemin d'accès au fichier où le modèle sera sauvegardé. Dans ce cas, le fichier s'appellera \"cifar10.h5\".\n","# - monitor : métrique à surveiller pour décider si le modèle doit être sauvegardé ou non. Dans ce cas, on surveille la précision sur le jeu de validation (\"val_acc\").\n","# - mode : mode de surveillance de la métrique. Dans ce cas, on souhaite maximiser la précision sur le jeu de validation, donc on utilise \"max\".\n","# - save_best_only : booléen indiquant si seul le meilleur modèle doit être sauvegardé ou non. Dans ce cas, on utilise \"True\" pour ne sauvegarder que le meilleur modèle."],"metadata":{"id":"RodDp1ongslF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras import metrics\n","\n","# Appel de la méthode compile du modèle\n","patch_model.compile(\n","    optimizer='adam',  # Utilisation de l'optimiseur Adam\n","    loss='binary_crossentropy',  # Utilisation de la perte 'binary_crossentropy' pour un problème de classification binaire\n","    metrics=['binary_accuracy']  # Utilisation des métriques binary_accuracy et F1-score\n",")"],"metadata":{"id":"_UBn31n2hxW6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 15\n","history = patch_model.fit(\n","    PA_train_dataset,  # Provide both inputs and labels to the model\n","    epochs=epochs,\n","    callbacks=[check_point, early_stopping]\n","  )"],"metadata":{"id":"IkNSewslqvRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the training and validation loss\n","plt.figure(figsize=(10, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"VTS7Hvpu76gW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()\n","model.save(\"geolife.h5\")"],"metadata":{"id":"uDhrmiiLq-4y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize an empty DataFrame\n","predictions_df = pd.DataFrame(columns=['surveyId', 'top_25_predictions'])\n","\n","# Make predictions on the test dataset\n","for i, (rgb_image, nir_image, survey_id) in enumerate(test_dataset):\n","    prediction = patch_model.predict([rgb_image, nir_image])\n","\n","    # Sort the predictions by probability in descending order and select the top 25\n","    top_25_indices = np.argsort(prediction)[-25:]\n","    top_25_predictions = prediction[top_25_indices]\n","    top_25_labels = mlb.classes_[top_25_indices]\n","\n","    # Convert the top 25 predictions to a space-separated string\n","    top_25_string = ' '.join(map(str, top_25_labels))\n","\n","    # Add the surveyId and top_25_predictions to the DataFrame\n","    new_row = pd.DataFrame({'surveyId': [survey_id], 'top_25_predictions': [top_25_string]})\n","    predictions_df = pd.concat([predictions_df, new_row], ignore_index=True)"],"metadata":{"id":"AiPn4epfAKFQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"bCZXEUF6rVGA"}}]}